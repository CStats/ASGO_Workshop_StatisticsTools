---
title: "Statistical software and applications"
subtitle: "Chris Brown, Univeristy of Sydney" 
#"AOFOG / ASGO Gyn Oncology Research Workshop 2025"
format:   
  revealjs:
    progress: true
    theme: serif
  pptx:
    toc: false
editor: visual
---

# Statistical software and applications

60min including questions / interaction

-   Questionnaire (5 mins)

-   Software (20 mins)

-   Statistical tests (30 mins)

-   Survey analysis / Questions (5 mins)

::: notes
```         
<https://redcap.sydney.edu.au/surveys/?s=EHCH7KRKT4THD3MN>
Set survey timestamp now!
```
:::

## Welcome survey {.r-fit-text layout-ncol="2"}

### Survey

![](images/clipboard-2128009121.png)

### Slides

-   Then check out these slides + example analysis code ([https://github.com/cstats](https://github.com/CStats/ASGO_Workshop_StatisticsTools){.uri})

::: notes
Set survey timestamp now! <https://redcap.sydney.edu.au/surveys/?s=EHCH7KRKT4THD3MN>
:::

## Who am I

-   1999 - 2002: BSc (Maths / Stats), University of Sydney

-   2002 - 2005: SPSS (Technical Support)

-   2004 - 2007: Masters Biostatistics

-   *2005 - Now: Clinical Trials Centre, University of Sydney*

-   2013 - 2015: Cancer Registry Ireland

-   *2016 - Now: Bean Bar You (Chocolate Subscription)*

::: notes
-   R \> SPSS \> SAS \> R
-   Today's prize for participating
:::

## Survey results

*Currently downloading and processing your results...*

```{r, echo=TRUE}
library(redcapAPI)

# Read token from API.txt
read.csv("API.txt", header=FALSE, stringsAsFactors=FALSE) -> api_key

# Connect to recap via API
rcon <- redcapConnection(
  url = "https://redcap.sydney.edu.au/api/",
  token = api_key[1,1]
)

# Download current responses
data <- exportRecordsTyped(rcon) 
```

```{r}
library(dplyr)
library(gtsummary)
library(ggplot2)
library(survival)
library(survminer)

data = data %>% 
  mutate(time = as.POSIXct(pre_timestamp)) %>% 
  mutate(time_diff = difftime(time,as.POSIXct("2025-11-14 14:00:00"),  units="mins")) %>% 
  filter(time_diff>0)
```

::: notes
-   slides written with "chunks" of R, generated using RStudio
:::

## Survey results - Statistics?

```{r}



data %>% 
  filter(!is.na(pre_timestamp)) %>% 
  mutate(statistics = as.numeric(statistics)) %>% 
  ggplot(aes(x=statistics))+
  geom_histogram()+
  geom_density(colour="blue")+
  xlab("What's your opinion of Statistics?")
```

## Survey results - Software?

```{r}
data %>% 
  filter(!is.na(pre_timestamp)) %>% 
  select(starts_with("software")) %>% 
  mutate(across(everything(), ~if_else(.x == "Checked", TRUE, FALSE))) %>%
  tbl_summary(
    label= list(
      "software___sas" = "SAS",
      "software___spss" = "SPSS",
      "software___stata" = "Stata",
      "software___r" = "R",
      "software___python" = "Python",
      "software___git" = "Git",
      "software___redcap" = "REDCap",
      "software___other" = "Other"
    ),
  )


```

## Survey results - Focus of this talk?

```{r}
data %>% 
  filter(!is.na(pre_timestamp)) %>% 
  mutate(content = as.numeric(content)) %>% 
  ggplot(aes(x=content))+
  geom_histogram()+
  geom_density(colour="blue")+
  xlab("Would you prefer session to spend more time on Software or Statistics?")+
  geom_text(aes(x=50, y=0.5,label="1 = More Software\n100 = More Statistics"),size=5
  )

```

## Survey results - Time to complete

```{r}
fit = survfit(Surv(as.numeric(time_diff), rep(1,nrow(data))) ~ 1, data = data)
#plot(fit)

ggsurvplot(
    fit,                     # survfit object with calculated statistics.
    data = data,  # data used to fit survival curves. 
    ylab="completed survey (%)",
    xlab="minutes",
    break.time.by = 3,
    conf.int = TRUE,
    legend = "none",#c(0.81,0.97),
    legned.title = "",
    #pval=TRUE,
    surv.scale = "percent",
    #xlim= c(0,28),
    break.y.by=0.1,
    surv.median.line = "hv",
    palette = c("darkblue","darkorange"),
    #Standard configuration
    risk.table = c("nrisk_cumcensor"),# show risk table.
    ggtheme = theme_survminer()+theme(),
    tables.theme = theme_void() + theme(plot.title = element_text(size =10)),
    risk.table.y.text.col = T, # colour risk table text annotations.
    risk.table.y.text = FALSE, # show bars instead of names in text annotations
    axes.offset=FALSE,
    risk.table.fontsize =3,
    tables.height=0.2,
)  
```

# Statistical Software

-   SAS

-   SPSS

-   Stata

-   R

-   Python

Other common tools:

-   REDCap

-   Git

::: notes
-   These are just the common ones (there are lots)

-   Outline for each: get from / how to use / tricks & tips

-   Excel is not a good solution

-   Programming may sound scary but it is worth it / very empowering
:::

## Popularity over time

![](images/clipboard-1326217817.png)

<https://www.kdnuggets.com/2010/06/software-popularity-of-data-analysis-software.html>

## SAS

<https://www.sas.com/>

-   Powerful / reliable / just works

-   Was the "standard" for pharmaceutical industry

-   Driven with code (programming)

-   Good sample size program (but is complicated)

-   Expensive / often available via Universities

![](images/clipboard-538516316.png){width="118"}

::: notes
-   Legion of fans: "SAS Certified"

-   Companies are diversifying and becoming comfortable with R/Python

-   First version 1967 -\> 9.2 2008, 9.3 2011, 9.4 2013
:::

## SAS screenshot

![](images/clipboard-1580301465.png)

::: notes
<https://sscc.wisc.edu/sscc/pubs/sas/SubmittingCode.html>
:::

## SPSS

<https://www.ibm.com/products/spss-statistics>

-   GUI (use menus and mouse to set up analyses)
-   Code option (SPSS Syntax) - Replicate your analysis!!!
-   Python integration (generate / interact with datasets)
-   Base + Add-Ins. \~\$150-300 USD/y. Student discounts

![](images/clipboard-2309160551.png)

::: notes
-   Popular in medical community (hospitals often have access, easy to use).

-   Syntax makes it reproducible

-   First version 1968
:::

## SPSS sample dataset

![](images/clipboard-383844906.png)

## SPSS screenshot

![](images/clipboard-378199739.png)

## SPSS data view

![](images/clipboard-1088338966.png)

## STATA

<https://www.stata.com/>

-   GUI well developed

-   Code is more integrated than in SPSS

-   Output text based but can now [create word doc / pdf / html](https://www.stata.com/features/overview/create-word-documents/)

-   USD \~160-510

![](images/clipboard-3606165708.png){width="185"}

::: notes
-   more popular in Europe?

-   (Heath) Economists love it.

-   Outputting of reports is a step forward

-   1985 first version
:::

## STATA screenshot

![](images/clipboard-179649262.png)

::: notes
<https://sscc.wisc.edu/sscc/pubs/sfs/sfs-ui.htm>
:::

## R

<https://cran.r-project.org/>

-   Open source (rebuild of a software called S+) = **Free**

-   Code based (People have created GUIs)

-   Huge community, great integrations (

-   [R-Studio](https://posit.co/products/open-source/rstudio/?sid=1) (Posit) fostered the "Tidyverse" which

-   Packages / can get messy / easy to break things

-   Markdown (Quarto) / Shiny = Game changers!

![](images/clipboard-4104427123.png)

::: notes
-   Flexibility has pros/cons

-   R markdown (text + code -\> report) was game changer

-   RStudio (now called "Posit") invested in the editor / packages that makes code easy

-   AI can help you write code
:::

## RStudio screenshot

![](images/clipboard-1974645368.png)

## R Reproducible research

-   [Literate programming (slides by Jenny Bryan)](https://www2.stat.duke.edu/~rcs46/lectures_2015/01-markdown-git/slides/lit-prog-slides/lit-prog-slides.pdf)

-   [R Markdown "The defintiive guide" Yihui Xie](https://bookdown.org/yihui/rmarkdown/)

    ![](images/clipboard-3883441198.png)

## R Shiny (Interactive

<https://shiny.posit.co/>

![](images/clipboard-3517705219.png)

::: notes
<https://gallery.shinyapps.io/006-tabsets/>
:::

## Python

<https://www.python.org/>

-   Not a traditional statistical software package

-   Pandas / NumPy / [Jupyter notebooks](https://jupyter.org/) -\> data science

-   Powerful, open source, huge community, AI

-   Open-source = FREE

-   Packages / can get messy / easy to break things

![](images/clipboard-2013306728.png){width="305"}

::: notes
-   Very powerful language, more than just statistics

-   Control computer / download/upload data / automate things

-   Jupyter notebooks facilitated research work

-   "Quarto" like R Markdown can run python

-   Embed GitHub Copilot in VSCode
:::

## Python - VSCode

![](images/clipboard-2579202323.png)

## Git

<https://git-scm.com/>

-   Version control text files (i.e. code)

-   Record changes over time + explanation of why

-   Able to roll-back to and old version

-   Very useful if collaborating with others

![](images/clipboard-3781116804.png){width="153"}

::: notes
-   not always easy dealing with branches / merges
-   even I had a mess with these lecture slides
:::

## Git - Problem

![](images/clipboard-3767456730.png)

## Git - Solution

![](images/clipboard-429044049.png)

## Git - Benefits

-   Backup and Restore.
-   Synchronization.
-   Short-term / long-term undo
-   Track changes
-   Track Ownership
-   Sandboxing
-   Branching and merging

<https://betterexplained.com/articles/a-visual-guide-to-version-control/>

::: notes
-   **Backup and Restore.** Files are saved as they are edited, and you can jump to any moment in time. Need that file as it was on Feb 23, 2007? No problem.

-   **Synchronization.** Lets people share files and stay up-to-date with the latest version.

-   **Short-term undo.** Monkeying with a file and messed it up? (That’s just like you, isn’t it?). Throw away your changes and go back to the “last known good” version in the database.

-   **Long-term undo.** Sometimes we mess up bad. Suppose you made a change a year ago, and it had a bug. Jump back to the old version, and see what change was made that day.

-   **Track Changes**. As files are updated, you can leave messages explaining why the change happened (stored in the VCS, not the file). This makes it easy to see how a file is evolving over time, and why.

-   **Track Ownership.** A VCS tags every change with the name of the person who made it. Helpful for [~~blamestorming~~](http://www.unwords.com/unword/blamestorming.html) giving credit.

-   **Sandboxing**, or insurance against yourself. Making a big change? You can make temporary changes in an isolated area, test and work out the kinks before “checking in” your changes.

-   **Branching and merging**. A larger sandbox. You can **branch** a copy of your code into a separate area and modify it in isolation (tracking changes separately). Later, you can **merge** your work back into the common area.
:::

## REDCap

<https://project-redcap.org/>

-   Open source database system

![](images/clipboard-246943709.png){width="654"}

## REDCap (example)

![](images/clipboard-3485340337.png)

# Statistical tests

|                       | H0 true           | H1 true                     |
|-----------------------|-------------------|-----------------------------|
| **Fail to reject H0** | Correct           | Type 2 ($\beta$)            |
| **Reject H0**         | Type 1 ($\alpha$) | Correct (Power = 1-$\beta$) |

## Randomisation

<https://heyspinner.com/random-number-wheel/1-2>

![](images/clipboard-287388969.png){width="507" height="468"}

::: notes
<https://heyspinner.com/random-number-wheel/1-2>
:::

## Types of data

## Types of data

-   Binary

-   Categorical (ordered/unordered)

-   Continuous

-   Time-to-event

## Common tests

-   Comparing proportions

-   Comparing continuous

-   Comparing time-to-event

## Example dataset

*From R's "survival" package: "cancer" dataset*

Survival in patients with advanced lung cancer from the North Central Cancer Treatment Group. Performance scores rate how well the patient can perform usual daily activities.

## Example dataset - Variables

| Variable  | Description                              |
|-----------|------------------------------------------|
| inst      | Institution code                         |
| time      | Survival time in days                    |
| status    | censoring status 1=censored, 2=dead      |
| age       | Age in years                             |
| sex       | Male=1 Female=2                          |
| ph.ecog   | ECOG as rated by the physician.          |
| ph.karno  | KPS (bad=0, good=100) rated by physician |
| pat.karno | rated by patient                         |
| meal.cal  | Calories consumed at meals               |
| wt.loss   | Weight loss in last six months (pounds)  |

::: notes
Karnofsky performance score
:::

# Proportions

```{r, include=FALSE}
library(dplyr)  # data manipulation / readable code
library(survminer) # pretty survival plots
library(survival) # survival analsis
library(gtsummary)  # nice summary tables

knitr::opts_chunk$set(echo = FALSE, warning=FALSE)  # don't print code in output

data(cancer, package="survival")  # load example dataset

cancer_clean <- cancer %>%
  mutate(
    Sex = factor(sex,c(1,2), labels=c("Male","Female")),
    Event = factor(status, levels=c(2,1), labels=c("Died","Censored")),
    ECOG = if_else(ph.ecog ==4, 3, ph.ecog),
    ECOG	= factor(ECOG , levels=c(0,1,2,3), labels=c("0","1","2","3/4")),
  )
```

## Power

```{r}
power.prop.test(n = 14, p1 = .2, p2 = NULL, sig.level = 0.05,
                power = .8,
                alternative = c("two.sided", "one.sided"),
                strict = FALSE, tol = .Machine$double.eps^0.25)
```

![](images/clipboard-759363916.png)

## Proportions in R

```{r, echo=TRUE}
tbl_cross(cancer_clean,
          row=Event,
          col=Sex,
          percent = "column"
) %>% 
add_p()
```

## Proportions in SPSS

![](images/clipboard-1864640983.png)

## Proportions in SPSS

![](images/clipboard-2806315982.png)

## Proportions in SPSS

![](images/clipboard-1068179763.png)

## Proportions in SPSS (tidy)

![](images/clipboard-2726006792.png)

## Proportions in Stata

![](images/clipboard-1170174040.png)

# Continuous

## T-Test in R

```{r, echo=TRUE}
tbl_summary(cancer_clean,
          include = c(age, meal.cal, wt.loss),
          statistic = list(all_continuous() ~ "{mean} ({sd})" ),
          by=sex
) %>% 
add_p(test=list(all_continuous() ~ "t.test"))

```

## T-Test in SPSS

![](images/clipboard-786410623.png)

## T-Test in Stata

![](images/clipboard-3233229489.png)

# Time to Event

## Time to event - Data

```{r}
cancer_data = cancer %>%  
  arrange(-time) %>%
  mutate(order = 1:n()) %>% 
  mutate(
    months = time/30.4375,
    sex = factor(sex, levels=c(1,2), labels=c("male","female")),
    age_10 = age/10,
    ecog = if_else(ph.ecog ==4, 3, ph.ecog),
    ecog	= factor(ecog , levels=c(0,1,2,3), labels=c("0","1","2","3/4")),
    ph.karno_10	 = ph.karno	/10,
    meal.cal_1000 = meal.cal/1000,
    wt.loss_10 = wt.loss/10
  )

cancer_data %>% 
  ggplot(aes(y=order, x=time))+
  geom_point(data=cancer_data %>% filter(status==1),shape=4)+
  geom_segment(aes(xstart=0, xend=time,yend=order),colour="black", x=0, alpha=0.5)+
  ylab("Participant (ordered by time)")+
  xlab("Time (days)")+
  ggtitle("Survival time (censored marked with x)")
```

::: notes
-   replace with example data + R plots
-   Assumption of "non-informative" censoring
:::

## Kaplan Meier

```{r, echo=TRUE}
fit <- survfit(Surv(time, status) ~ 1, data = cancer)
plot(fit)
```

## Kaplan Meier - Stata

![](images/clipboard-2096223799.png){width="263"}

![](images/clipboard-2089031291.png){width="592"}

## Kaplan Meier - SPSS

![](images/clipboard-3216427961.png)

## Kaplan Meier - SPSS

![](images/clipboard-1985207386.png)

## Kaplan Meier - SPSS

![](images/clipboard-3090162493.png)

## Log-rank test

```{r}

    

fit <- survfit(Surv(months, status) ~ sex, data= cancer_data)


ggsurvplot(
    fit,                     # survfit object with calculated statistics.
    data = cancer_data,  # data used to fit survival curves. 
    ylab="overall survival (%)",
    xlab="months",
    break.time.by = 3,
    conf.int = FALSE,
    legend = c(0.81,0.97),
    legned.title = "",
    pval=TRUE,
    surv.scale = "percent",
    xlim= c(0,28),
    break.y.by=0.1,
    surv.median.line = "hv",
    palette = c("darkblue","darkorange"),
    #Standard configuration
    risk.table = c("nrisk_cumcensor"),# show risk table.
    ggtheme = theme_survminer()+theme(),
    tables.theme = theme_void() + theme(plot.title = element_text(size =10)),
    risk.table.y.text.col = T, # colour risk table text annotations.
    risk.table.y.text = FALSE, # show bars instead of names in text annotations
    axes.offset=FALSE,
    risk.table.fontsize =3,
    tables.height=0.2,
)
```

::: notes
-   log rank statistic: essentially squared difference between the average of the two curves / variance of this.
:::

## Median follow-up

```{r}
followup <- survfit(Surv(months, status==1) ~ 1, data = cancer_data)
```

```{r}
ggsurvplot(
    followup,                     # survfit object with calculated statistics.
    data = cancer_data,  # data used to fit survival curves. 
    ylab="alive with follow-up (%)",
    xlab="months",
    break.time.by = 6,
    conf.int = FALSE,
    legend = c(0.81,0.97),
    legned.title = "",
    pval=TRUE,
    surv.scale = "percent",
    #xlim= c(0,28),
    break.y.by=0.1,
    surv.median.line = "hv",
    palette = c("blue"),
    #Standard configuration
    risk.table = c("nrisk_cumcensor"),# show risk table.
    ggtheme = theme_survminer()+theme(),
    tables.theme = theme_void() + theme(plot.title = element_text(size =10)),
    risk.table.y.text.col = T, # colour risk table text annotations.
    risk.table.y.text = FALSE, # show bars instead of names in text annotations
    axes.offset=FALSE,
    risk.table.fontsize =3,
    tables.height=0.2,
)
```

## Competing risks

![](images/clipboard-957385996.png)

## Competing risk - CI

![](images/clipboard-4017955626.png)

# Modelling

-   Regression

    -   UV

    -   MV

    -   Repeated measures / clustering

-   Time to event

    -   Cox-proportional hazards

    -   Competing risks

## Cox Regression - Hazards

![](images/clipboard-1766806917.png)

## Cox Regression - Hazards

![](images/clipboard-1741160324.png)

## Proportional hazards

![](images/clipboard-2495711226.png)

-   Hazard Ratio: The average ratio of these two lines (over the whole period)

## Proportional hazards

![](images/clipboard-3678869280.png)

-   'Baseline hazard' can take any form (i.e. doesn't have to be constant / smooth)

## Non-proportional hazards

![](images/clipboard-3729452211.png)

-   Can appear as curves "crossing" or "diverging"

-   If so, a single number (hazard ratio) may not be the appropriate summary

## Non-proportional hazards

![](images/clipboard-2872613344.png){width="546"}

![](images/clipboard-2755459745.png)

## Sub-groups

![](images/clipboard-3186113513.png)

## Cox regression in R

```{r, echo=TRUE}
cox_model = coxph(Surv(time, status) ~ sex, data = cancer)
summary(cox_model)
```

## Cox regression in R

```{r, echo=TRUE}
tbl_regression(cox_model,
               exponentiate = TRUE) %>% 
  add_global_p()

test.ph <-cox.zph(cox_model)
ggcoxzph(test.ph)

```

## Time dependent Cox

![](images/clipboard-3627009564.png)

## Univariable models {.r-fit-text}

```{r}
tbl_uvregression(
  method = coxph,
  include = c(sex, age, age_10, ph.ecog, ecog, ph.karno_10, meal.cal_1000, wt.loss_10),
  y = Surv(time, status),
  exponentiate = TRUE,
  data = cancer_data
) %>%
  add_global_p()
```

::: note
-   age vs age_10?
-   ph.ecog vs ecog?
:::

## Multivariable models

```{r}
m2 <- coxph(Surv(months,status) ~ sex + age_10 + ecog + ph.karno_10 + meal.cal_1000 + wt.loss_10, data= cancer_data)
tbl_regression(m2, exponentiate=TRUE)
```

## Model selection

-   Consider your context and objective

-   ~~Backwards / forwards selection~~

-   Best subset

-   LASSO regression

Want to learn more? Suggest Frank Harrell, Regression Modelling Strategies. <https://hbiostat.org/rmsc/>

::: notes
Lasso (Least Absolute Shrinkage and Selection Operator) which is a penalised regression (some coefficients shrink to 0).
:::

## Repeated measures / clustering

-   Mixed effects logistic regression

-   Generalised estimating equations (GEE) 

    ![](images/clipboard-584745290.png){width="460"}

[Katherine E. Francis, Reporting the trajectories of adverse events over the entire treatment course....](https://www.sciencedirect.com/science/article/pii/S0959804921000733)

# Summary

-   Use any package (one you can get support with)

-   Have a reproducible mindset (make life easy)

-   Use version control (keep things tidy)

-   Write comments for "future you" / others

## GitHub Copilot

<https://docs.github.com/en/copilot>

![](images/clipboard-1582934450.png)

## Reproducible mindset

Aim to be able to run from s**ource program** to **output report** without manual intervention:

-   You won't forget how to run / update things (+5 years)

-   Someone else can run it if they want to

-   You can't make copy/paste / typing errors

-   Automatic updates (if you the data changes)

[My poster: Embedding reproducible research principals in clinical trial analyses](https://figshare.com/articles/poster/Embedding_reproducible_research_principals_in_clinical_trial_analyses/9929735?file=17868944)

## Survey part 2

Please complete the 2nd part of the survey now... I really appreciate your feedback (use QR only if lost the page)

![](images/clipboard-2128009121.png)

## ACORD 2026

Want to develop an trial idea into a full protocol in 6 days?

Consider an ACORD protocol development workshop

<https://www.moga.org.au/2026-acord-workshop>

![](images/clipboard-3798916481.png)

# Thank you

Any questions?
